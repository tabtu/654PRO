multimodal access w3c w3c standards participate membership about w3c site navigation web of devices voice browsing device independence and content adaptation multimodal access web and tv skip w3c standards web of devices multimodal access multimodal access on this page what is multimodal access capabilities of multimodal access examples learn more current status of specifications and groups what is multimodal access multimodal technology is a promising candidate of future human machine interfaces which can improve web accessibility within various conditions and environments of the users. for example these days we can access the web using various devices including mobile phones pda car navigation system and home appliances. however the concrete access methods strongly depend on the type of devices and services and are quite different from each other. some of those applications are based on w3c standards. however many are based on proprietary platforms and technologies. so a global and universal standardized mechanism which applies to various kinds of devices and services is required to materialize one web which lets any person to access a specific information using any modalities on any devices from anywhere at any time. capabilities of multimodal access the capabilities of multimodal applications include voice and gui interaction. standards for multimodal interfaces should be scalable to enable richer capabilities for subsequent generations of multimodal devices. to encourage rapid adoption the same content can be designed for use on both old simple and new multimodal devices. for example people with new multimodal devices will get to experience their multimodal capabilities while users with old simple devices will get to use the keypad and or stylus in the same way as now. users of multimodal devices will be able to provide input via speech handwriting or keystrokes with output presented via displays pre-recorded and synthetic speech audio and tactile mechanisms like vibrators and braille strips. application developers will be able to provide an effective user interface for whichever modes the user selects. examples as a result of increasingly capable networks devices and speech recognition technology the number of existing multimodal applications especially mobile applications is rapidly accelerating multimodal voice search integrating gui and speech voice control on mobile devices address input on gps systems multimodal in-car systems for accessing navigation and audio visual control note that almost all of those multimodal applications have appeared in the last two years. many of them are based on proprietary platforms and technologies so standardization of multimodal interfaces is needed for global interoperability. learn more the mission of the multimodal interaction activity is to develop open standards that enable the following vision extending the web to allow multiple modes of interaction gui speech vision pen gestures haptic interfaces anyone anywhere any device any time accessible through the user s preferred modes of interaction with services that adapt to the device user and environmental conditions visit the multimodal interaction activity home page. recent w3c press releases and member testimonials digital ink standard enhances device integration 20 september 2011 current status of specifications learn more about the current status of specifications related to inkml multimodal web applications these w3c groups are working on the related specifications multimodal interaction working group contact kazuyuki ashimura ashimura@w3.org current status inkml multimodal web applications use it tutorials business case software footer navigation navigation home standards participate membership about w3c contact w3c contact help and faq donate site map feedback w3c updates copyright 2013 w3c mit ercim keio beihang usage policies apply. 