best practices for creating mmi modality components best practices for creating mmi modality components w3c working group note 1 march 2011 this version http www.w3.org tr 2011 note-mmi-mcbp-20110301 latest version http www.w3.org tr mmi-mcbp previous version this is the first version. editor ingmar kliche deutsche telekom ag authors deborah dahl invited expert james a. larson invited expert b. helena rodriguez telecom paristech muthuselvam selvaraj until 2009 while at hp copyright 2011 w3c mit ercim keio all rights reserved. w3c liability trademark and document use rules apply. abstract this document describes modality components in the mmi architecture which are responsible for controlling the various input and output modalities on various devices by providing guidelines and suggestions for designing modality components. also this document shows several possible examples of modality components 1 face identification 2 form-filling using handwriting recognition and 3 video display. status of this document this section describes the status of this document at the time of its publication. other documents may supersede this document. a list of current w3c publications and the latest revision of this technical report can be found in the w3c technical reports index at http www.w3.org tr this is the 1 march 2011 w3c working group note of best practices for creating mmi modality components the multimodal interaction working group once published a working draft of the multimodal architecture and interfaces mmi architecture on 16 october 2008 with this content. however the working group concluded that the description on how to create modality components and examples of possible modality components should be published as a working group note rather than part of the mmi architecture specification. the goal of this working group note is to provide guidelines and suggestions for designing modality components in the mmi architecture and make it easier to author concrete modality components for multimodal web applications. also this document shows several possible examples of modality components 1 face identification 2 form-filling using handwriting recognition and 3 video display. this w3c working group note has been developed by the multimodal interaction working group of the w3c multimodal interaction activity. comments for this note are welcomed and should have a subject starting with the prefix arch please send them to www-multimodal@w3.org the public email list for issues related to multimodal. this list is archived and acceptance of this archiving policy is requested automatically upon first post. to subscribe to this list send an email to www-multimodal-request@w3.org with the word subscribe in the subject line. for more information about the multimodal interaction activity please see the multimodal interaction activity statement. this document was produced by a group operating under the 5 february 2004 w3c patent policy. w3c maintains a public list of any patent disclosures made in connection with the deliverables of the group that page also includes instructions for disclosing a patent. an individual who has actual knowledge of a patent which the individual believes contains essential claim s must disclose the information in accordance with section 6 of the w3c patent policy. publication as a working group note does not imply endorsement by the w3c membership. this is a draft document and may be updated replaced or obsoleted by other documents at any time. it is inappropriate to cite this document as other than work in progress. table of contents 1 introduction 2 modality component guidelines 2.1 guideline 1 each modality component must implement all of the mmi life-cycle events. 2.2 guideline 2 identify other functions of the modality component that are relevant to the interaction manager. 2.3 guideline 3 if the component uses media specify the media format. for example audio formats for speech recognition or inkml for handwriting recognition. 2.4 guideline 4 specify protocols for use between the component and the interaction manager im e.g. sip or http 2.5 guideline 5 specify supported human languages e.g. english german chinese and locale if relevant. 2.6 guideline 6 specify supporting languages required by the component if any. 2.7 guideline 7 modality components sending data to the interaction manager must use the format where appropriate. 2.8 guideline 8 specify error codes and their meanings to be returned to the im. 3 modality component design suggestions 3.1 design suggestion 1 consider constructing a complex modality component with multiple functions if one function handles the errors generated by another function. 3.2 design suggestion 2 consider constructing a complex modality component with multiple functions rather than several simple modality components if the functions need to be synchronized. 3.3 design suggestion 3 consider constructing a nested modality component with multiple child modality components if the children modality components are frequently used together but do not handle ther errors generated by the other children components and the children components do not need to be extensively synchronized. 4 example simple modality face identification 4.1 functions of a possible face identification component 4.2 event syntax 4.2.1 examples of events for starting the component 4.2.2 example output event 5 example simple modality form-filling using handwriting recognition 5.1 functions of a possible handwriting recognition component 5.2 event syntax 5.2.1 examples of events for preparing the component 5.2.2 examples of events for starting the component 5.2.3 example output event 6 example simple modality video display 6.1 functions of a possible video display component 6.2 event syntax 6.2.1 examples of events for starting the component appendix a references 1 introduction the w3c multimodal interaction mmi working group develops an architecture mmi-arch for the multimodal interaction framework mmif the multimodal architecture describes a general and flexible framework for interoperability of the various components of the multimodal framework e.g. modality components mc and the interaction manager im in an abstract way. among others it defines interfaces and messages between the constituents of the framework but it is up to the implementation to decide how these messages are transferred in case of a distributed implementation. this note is an informative supplement to the multimodal architecture and interfaces specification mmi-arch in contrast to the multimodal architecture specification which defines normative conformance for multimodal constituents the intention of this document is to provide additional informative guidelines for authors of mmi modality components. its purpose is to assist authors in maximizing the usefulness of their multimodal architecture conformant constituents by describing additional information which will enable constituents to be more easily incorporated into a multimodal system. this additional suggested information includes for example descriptions of how the constituent behaves with respect to the optional aspects of the architecture. the specific goals of the guidelines in this document are to promote interoperability when constituents from different vendors are used in the same system by suggesting important information that can be provided along with a constituent that will enable others to use the constituent effectively 2 modality component guidelines provide suggestions for authoring modality components in order to maximize their effectiveness 3 modality component design suggestions provide illustrations of these suggestions using sample modality components for face identification and handwriting recognition 4 example simple modality face identification and 5 example simple modality form-filling using handwriting recognition 2 modality component guidelines the following guidelines guarantee that modalities are portable from interaction manager to interaction manager. 2.1 guideline 1 each modality component must implement all of the mmi life-cycle events. the mmi life-cycle events are the mechanism through which a modality component communicates with the interaction manager. the modality component mc author must define how the modality component will respond to each life-cycle event. a modality component must respond to every life-cycle event it receives from the interaction manager in the cases where a response is required as defined by the mmi architecture. for example if a modality component presents a static display it must respond to a pause event with a pauseresponse event even if the static display modality component does nothing else in response to the pause event. for each life-cycle event define the parameters and syntax of the data element of the corresponding the life-cycle event that will be used in performing that function. for example the startrequest event for a speech recognition modality component might include parameters like timeout confidence threshold max n-best and grammar. 2.2 guideline 2 identify other functions of the modality component that are relevant to the interaction manager. define an extensionnotification event to communicate these functions to and from the interaction manager. 2.3 guideline 3 if the component uses media specify the media format. for example audio formats for speech recognition or inkml for handwriting recognition. 2.4 guideline 4 specify protocols for use between the component and the interaction manager im e.g. sip or http 2.5 guideline 5 specify supported human languages e.g. english german chinese and locale if relevant. 2.6 guideline 6 specify supporting languages required by the component if any. for example ssml for a speech synthesis simple modality component srgs and sisr for a speech recognition simple modality component voicexml ssml srgs and sisr for a speech complex modality component 2.7 guideline 7 modality components sending data to the interaction manager must use the emma format where appropriate. if a modality component captures or generates information then it should format the information using the emma format and use an extension event to send that information to the interaction manager. 2.8 guideline 8 specify error codes and their meanings to be returned to the im. the mc developer must specify all error codes that are specific to the component. if the mc is based on another technology the developer can provide a reference to that technology specification. for instance if the mc is based on voicexml a reference to the voicexml spec for voicexml errors can be included instead of listing each voicexml error. errors such as xml errors and mmi protocol errors must be handled in accordance with the guidelines laid out in the mmi architecture. these errors do not need to be documented. 3 modality component design suggestions the following design suggestions should be helpful for modality component authors to make modalities portable from interaction manager to interaction manager. 3.1 design suggestion 1 consider constructing a complex modality component with multiple functions if one function handles the errors generated by another function. for example if the asr fails to recognize a user s utterance a prompt may be presented to the user asking the user to try again by the tts function. as another example if the asr fails to recognize a user s utterance a gui function might display the n-best list on a screen so the user can select the desired word. efficiency concerns may indicate that two modality components be combined into a single complex modality component. 3.2 design suggestion 2 consider constructing a complex modality component with multiple functions rather than several simple modality components if the functions need to be synchronized. for example a tts function must be synchronized with a visual talking head so that the lip movements are synchronized with the words. as another example a tts functions presents information about the each graphical item that the user places in focus. again efficiency concerns may indicate that the tts and talking head be two modality components be combined into a single complex modality component. 3.3 design suggestion 3 consider constructing a nested modality component with multiple child modality components if the children modality components are frequently used together but do not handle ther errors generated by the other children components and the children components do not need to be extensively synchronized. writing an application using a nested modality component may be easier than writing the same application using multiple modality components if the nested modality component hides much of the complexity of managing the children modality components. 4 example simple modality face identification 4.1 functions of a possible face identification component consider a theoretical face identification modality component that takes an image or images of a face and returns the set of possible matches and the confidence of the face identification software in each match. an api to that modality component would include events for starting the component providing data and for receiving results back from the component. this particular example includes the information needed to run this component in the startrequest and donenotification events that is in this example no extensionnotification events are used although extensionnotification events could be part of another modality component s api. this example assumes that an image has already been acquired from some source however another possibility would be to also include image acquisition in the operation of the component. depending on the capabilities of the modality component other possible information that might be included would be some useful non-functional information as the capturing context of the still picture e.g. indoor picture or outdoor picture or the type of image e.g. a portrait photography or a street photography or would be some technical information as the algorithm to be used or the image format to expect. we emphasize that this is just an example to indicate the kinds of information that might be used by a multimodal application that includes face recognition. the actual interface used in real applications should be defined by experts in the field. the use case is a face identification component that identifies one of a set of employees on the basis of face images. the mmi runtime framework could use the following events to communicate with such a component. table 1 component behavior of face identification with respect to modality component guidelines. guideline component information guideline 1 each modality component must implement all of the mmi life cycle events. see table 2 for the details of the implementation of the life-cycle events. guideline 2 identify other functions of the modality component that are relevant to the interaction manager. all the functions of the component are covered in the life-cycle events no other functions are needed. guideline 3 if the component uses media specify the media format. the component uses the jpeg format for images to be identified and for its image database. guideline 4 specify protocols supported by the component for transmitting media e.g. sip the component uses http for transmitting media. guideline 5 specify supported human languages. this component does not support any human languages. guideline 6 specify supporting languages required by the component. this component does not require any markup languages. guideline 7 modality components sending data to the interaction manager must use the emma format. this component uses emma. table 2 component behavior of face identification for each life-cycle event. life cycle event component implementation newcontextrequest standard the component requests a new context from the im. newcontextresponse standard the component starts a new context and assigns the new context id to it. preparerequest the component prepares resources to be used in identification specifically the image database. prepareresponse standard if the database of known users is not found the error message known users not found is returned in the statusinfo element. startrequest the component starts processing if possible using a specified image image database threshold and limit on the size of nbest results to be returned. startresponse standard if the database of known users is not found the error message known users not found is returned in the statusinfo element. donenotification identification results in emma format are reported in the data field.the mode is photograph the medium is visual the function is identification and verbal is false cancelrequest this component stops processing when it receives a cancelrequest it always performs a hard stop whether or not the im requests a hard stop. cancelresponse standard pauserequest this component cannot pause. pauseresponse statusinfo field is cannot pause resumerequest this component cannot resume. resumeresponse statusinfo field is cannot resume extensionnotification this component does not use extensionnotification it ignores any extensionnotification events that are sent to it by the im. clearcontextrequest standard clearcontextresponse standard statusrequest standard statusresponse the component returns a standard life cycle response. the automaticupdate attribute is false because this component does not supply automatic updates. note standard means that the component does not do anything over and above the actions specified by the mmi architecture. 4.2 event syntax 4.2.1 examples of events for starting the component to start the component a startrequest event from the im to the face identification component is sent asking it to start an identification. it assumes that images found at a certain uri are to be identified by comparing them against a known set of employees found at another uri. the confidence threshold of the component is set to 5 and the im requests a maximum of five possible matches. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startrequest source uri rtfuri context uri-1 requestid request-1 mmi data face-identification-parameters threshold 5 unknown someuri known uri employees max-nbest 5 mmi data mmi startrequest mmi mmi as part of support for the life-cycle events a modality component is required to respond to a startrequest event with a startresponse event. here s an example of a startresponse from the face identification component to the im informing the im that the face identification component has successfully started. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri faceuri context uri-1 requestid request-1 status success mmi mmi here s an example of a startresponse event from the face identification component to the im in the case of failure with an example failure message. in this case the failure message indicates that the known images cannot be found. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri faceuri context uri-1 requestid request-1 status failure mmi statusinfo known users not found mmi statusinfo mmi startresponse mmi mmi 4.2.2 example output event here s an example of an output event sent from the face identification component to the im using emma to represent the identification results. two results with different confidences are returned. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi donenotification source uri faceuri context uri-1 status success requestid request-1 mmi data emma emma version 1.0 xmlns emma http www.w3.org 2003 04 emma emma one-of emma medium visual emma verbal false emma mode photograph emma function identification emma interpretation id int1 emma confidence 75 person 12345 person name mary smith name emma interpretation emma interpretation id int2 emma confidence 6 person 67890 person name jim jones name emma interpretation emma one-of emma emma mmi data mmi donenotification mmi mmi this is an example of emma output in the case where the face image doesn t match any of the employees. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi donenotification source uri faceuri context uri-1 status success requestid request-1 mmi data emma emma version 1.0 xmlns emma http www.w3.org 2003 04 emma emma interpretation id int1 emma confidence 0.0 uninterpreted true emma medium visual emma mode photograph emma function identification emma emma mmi data mmi donenotification mmi mmi 5 example simple modality form-filling using handwriting recognition 5.1 functions of a possible handwriting recognition component consider an ink recognition modality component for handwriting recognition hwr that takes digital ink written using an electronic pen or stylus performs recognition and returns the recognized text. an api to such a modality component would include events for initializing the component requesting for recognition by providing digital ink data and for receiving recognized text result possibly an n-best list back from the component as shown in the below figure. figure 1 example of japanese handwriting recognition this example assumes that handwriting ink is captured represented in w3c inkml format and sent to the im requesting for recognition to text. the following sequences of events explain the ink recognition request. the im requests the ink recognition modality by sending the preparerequest event along with the parameters for configuring the hwr system. ink recognition modality responds with the prepareresponse event with the status of the configuration of the hwr system. im sends the startrequest event to the ink recognition modality where the event s data field contains the inkml data to be recognized. once the recognition is completed the ink recognition modality notifies the results to the im using the donenotification event along with the recognition choices n-best list the use case is a form-filling application which accepts handwriting input provided by the user on the form fields. the inputs are recognized and displayed back as text in the corresponding fields. an ink capture modality may be used to capture the ink and send it to im for recognition. the communication between the ink capture modality and the im is not covered here for the sake of brevity. the below section explains the details of the communication between the mmi runtime framework rtf of the im and the ink recognition modality. table 3 component behavior of ink modality with respect to modality component guidelines. guideline component information guideline 1 each modality component must implement all of the mmi life cycle events. see table 4 for the details of the implementation of the life-cycle events. guideline 2 identify other functions of the modality component that are relevant to the interaction manager. all the functions of the component are covered in the life-cycle events no other functions are needed. guideline 3 if the component uses media specify the media format. the component uses w3c inkml format to represent handwriting data digital ink guideline 4 specify protocols supported by the component for transmitting media e.g. sip the component uses http for transmitting media. other standard protocols such as tcp may also be explored. guideline 5 specify supported human languages. virtually any human language script can be supported based on the hwr component capability. guideline 6 specify supporting languages required by the component. w3c inkml for representing the handwriting data. guideline 7 modality components sending data to the interaction manager must use the emma format. this component uses emma. table 4 component behavior of handwriting recognition for each life-cycle event. life cycle event component implementation newcontextrequest standard the component requests a new context from the im. newcontextresponse standard the component starts a new context and assigns the new context id to it. preparerequest the component prepares resources to be used in recognition. based on the script parameter it first selects an appropriate recognizer. it also configures the recognizer with other parameters such as recognition confidence threshold limit on the size of n-best results to be returned etc. when available. prepareresponse standard if the recognizer failed to find a matching recognizer for the request language script a relevant error message is returned in the statusinfo element. startrequest the component performs recognition of the handwriting input. startresponse standard the status of recognition as success or failure is returned in the statusinfo element. donenotification identification results in emma format are reported in the data field. the mode is ink the medium is tactile the function is transcription and verbal is true cancelrequest this component stops processing when it receives a cancelrequest it always performs a hard stop irrespective of the im request. cancelresponse standard pauserequest this component cannot pause. pauseresponse statusinfo field is cannot pause resumerequest this component cannot resume. resumeresponse statusinfo field is cannot resume extensionnotification this component does not use extensionnotification it ignores any extensionnotification events that are sent to it by the im. clearcontextrequest standard clearcontextresponse standard statusrequest standard statusresponse the component returns a standard life cycle response. the automaticupdate attribute is false because this component does not supply automatic updates. note standard means that the component does not do anything over and above the actions specified by the mmi architecture. 5.2 event syntax 5.2.1 examples of events for preparing the component im send a preparerequest event to the ink recognition component. the ink recognition component selects an appropriate recognizer that matches the given language script in this example it is set to english_lowercase the recogrammar.xml grammar file contains constraints that aid the recognizer. the confidence threshold of the component is set to 7 and the im requests a maximum of five possible matches. based on the capability of the recognizer other possible parameters such as a user profile that contains user-specific information can be provided. mmi mmi version 1.0 xmlns mmi http www.w3.org 2008 04 mmi-arch mmi preparerequest source uri rtfuri context uri-1 requestid request-1 mmi data ink-recognition-parameters grammar recogrammar.xml threshold 7 script english_lowercase max-nbest 5 mmi data mmi preparerequest mmi mmi as part of support for the life cycle events a modality component is required to respond to a preparerequest event with a prepareresponse event. here s an example of a prepareresponse from the ink recognition component to the im informing the im that the ink recognition component has successfully initialized. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi prepareresponse source uri inkrecognizeruri context uri-1 requestid request-1 status success mmi mmi here s an example of a prepareresponse event from the ink recognition component to the im in the case of failure with an example failure message. in this case the failure message indicates that the language script is not supported. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi prepareresponse source uri inkrecognizeruri context uri-1 requestid request-1 status failure mmi statusinfo given language script not supported mmi statusinfo mmi prepareresponse mmi mmi 5.2.2 examples of events for starting the component to start the component and recognize the handwriting data a startrequest event from the im to the ink recognition component is sent. the data field of the event contains inkml representation of the ink data. along with the ink additional information such as the reference co-ordinate system and capture device s resolution may also be provided in the inkml data. the below example shows that the ink strokes have x and y channels and the ink has been captured at a resolution of 1000 dpi. the example ink data contains strokes of the japanese character 手 te which means hand mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi startrequest source uri inkrecognizeruri context uri-1 requestid request-1 mmi data ink ink version 1.0 xmlns ink http www.w3.org 2003 inkml ink definitions ink context id device1context ink traceformat id strokeformat ink channel name x type decimal ink channelproperty name resolution value 1000 units 1 in ink channel ink channel name y type decimal ink channelproperty name resolution value 1000 units 1 in ink channel ink traceformat ink context ink definitions ink tracegroup contextref device1context ink trace 106 81 105 82 104 84 103 85 101 88 100 90 99 91 97 97 89 105 88 107 87 109 86 110 84 111 84 112 82 113 78 117 74 121 72 122 70 123 68 125 67 125 66 126 65 126 63 127 57 129 53 133 47 135 46 136 45 136 44 137 43 137 43 137 ink trace ink trace 28 165 29 165 31 165 33 165 35 164 37 164 38 164 40 163 42 163 45 163 49 162 51 162 53 162 56 162 58 162 64 160 69 160 71 159 74 159 76 159 78 159 86 157 91 157 95 157 96 157 99 157 101 157 103 157 109 155 111 155 114 155 116 155 119 155 121 154 124 154 126 154 127 154 129 154 131 154 134 153 135 153 136 153 137 153 138 153 139 153 140 153 141 153 142 153 143 153 144 153 145 153 145 153 ink trace ink trace 10 218 12 218 14 218 20 216 25 216 28 216 31 216 34 216 37 216 45 216 53 216 58 215 60 215 63 215 68 215 72 215 74 215 77 215 85 212 88 212 94 210 100 208 105 208 107 208 109 208 110 208 111 207 114 207 115 207 119 207 121 207 123 207 124 207 128 206 130 205 131 205 134 205 136 205 137 205 138 205 139 204 140 204 141 204 142 204 143 204 144 204 145 204 146 204 147 204 148 204 149 204 150 204 151 203 152 203 153 203 154 203 155 203 156 203 158 203 159 202 160 202 161 202 162 202 163 202 164 202 165 202 166 202 167 202 168 202 169 202 170 202 171 202 172 202 173 202 173 201 173 201 ink trace ink trace 78 128 78 127 79 127 79 128 80 129 80 130 81 132 82 133 82 134 83 135 84 137 85 139 86 141 87 142 88 144 89 146 94 152 95 153 96 155 98 160 99 162 100 165 101 167 101 169 102 173 102 176 102 181 102 183 102 185 102 186 104 192 104 195 104 197 104 199 104 201 104 203 104 205 104 206 104 207 104 208 104 209 104 210 104 211 104 213 104 214 104 215 104 216 104 217 104 218 104 220 103 222 102 223 102 224 102 223 102 224 103 225 103 228 103 229 103 230 103 231 103 232 103 233 103 236 103 239 103 242 103 243 103 247 103 248 102 249 102 250 102 251 101 251 100 253 99 255 99 256 98 257 97 258 97 259 96 260 96 261 95 262 95 263 94 264 94 265 93 266 93 267 92 268 91 269 91 270 90 271 90 272 89 273 89 274 88 275 88 276 87 276 87 277 86 277 86 278 85 279 85 280 84 281 83 282 82 284 82 285 81 285 80 286 79 287 78 288 77 288 77 289 76 290 75 290 75 291 74 291 74 290 74 289 74 288 74 287 73 287 73 286 73 285 72 284 72 281 71 280 70 279 70 278 69 277 68 276 67 275 65 274 62 272 60 271 59 271 58 270 57 270 56 269 55 268 54 268 53 267 52 267 51 267 49 267 48 267 48 266 48 266 ink trace ink tracegroup ink ink mmi data mmi startrequest mmi mmi as part of support for the life cycle events a modality component is required to respond to a startrequest event with a startresponse event. here s an example of a startresponse from the ink recognition component to the im informing the im that the ink recognition component has successfully started. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri inkrecognizeruri context uri-1 requestid request-1 status success mmi mmi here s an example of a startresponse event from the ink recognition component to the im in the case of failure with an example failure message. in this case the failure message indicates that the recognition failed due to invalid data format of the handwriting data. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri inkrecognizeruri context uri-1 requestid request-1 status failure mmi statusinfo invalid data format mmi statusinfo mmi startresponse mmi mmi 5.2.3 example output event here s an example of an output event sent from the ink recognition component to the im using emma to represent the identification results. two results with different confidences are returned. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi donenotification source uri inkrecognizeruri context uri-1 status success requestid request-1 mmi data emma emma version 1.0 xmlns emma http www.w3.org 2003 04 emma emma one-of emma medium tactile emma verbal true emma mode ink emma function transcription emma interpretation id int1 emma confidence 8 text 手 text emma interpretation emma interpretation id int2 emma confidence 7 text 于 text emma interpretation emma one-of emma emma mmi data mmi donenotification mmi mmi this is an example of emma output in the case where the recognizer is unable to find a suitable match to the input handwriting. the emma output contains an empty interpretation result. mmi mmi xmlns mmi http www.w3.org 2008 04 mmi-arch version 1.0 mmi donenotification source uri inkrecognizeruri context uri-1 status success requestid request-1 mmi data emma emma version 1.0 xmlns emma http www.w3.org 2003 04 emma emma interpretation id int1 emma confidence 0.0 emma medium tactile emma verbal true emma mode ink emma function transcription emma uninterpreted true emma emma mmi data mmi donenotification mmi mmi 6 example simple modality video display 6.1 functions of a possible video display component consider a theoretical video display modality component that receives a video file and displays it in a screen. an api to that modality component would include events for starting the component providing the video file and for receiving player status information back from the component. this example includes the information needed to run this component in the startrequest event and shows a display codec problem. in order to focus in the behavior of the output modality component this example assumes that the video file is given from some source however another possibility would be to also include video acquisition in a composite input output and more complex real-time display component. depending on the capabilities of the modality component other possible information that might be included would be the video formats supported. the mmi runtime framework could use the following events to communicate with such a component. table 5 component behavior of video display with respect to modality component guidelines. guideline component information guideline 1 each modality component must implement all of the mmi life cycle events. see table 6 for the details of the implementation of the life-cycle events. guideline 2 identify other functions of the modality component that are relevant to the interaction manager. all the functions of the component are covered in the life-cycle events no other functions are needed. guideline 3 if the component uses media specify the media format. the component uses for the moment only the h.264 codec format. guideline 4 specify protocols supported by the component for transmitting media e.g. sip the component uses http for transmitting media. guideline 5 specify supported human languages. this component does not support any human languages. guideline 6 specify supporting languages required by the component. this component does not require any markup languages. guideline 7 modality components sending data to the interaction manager must use the emma format. this component uses emma. table 6 component behavior of video display for each life-cycle event. life cycle event component implementation newcontextrequest standard the component requests a new context from the im. newcontextresponse standard the component starts a new context and assigns the new context id to it. preparerequest the component prepares resources to be used in display configuration specifically the supported formats table. prepareresponse standard if the recognizer failed to find a matching recognizer for the request language script a relevant error message is returned in the statusinfo element. startrequest the component starts displaying video if possible. the mmi data element might hold a video-display-parameters element containing a videofile attribute. the videofile attribute contains the uri referencing the video content. startresponse standard if the current video format wvm is not found in the supported codec formats table the error message codec not supported is returned in the statusinfo element. donenotification display state in emma format are reported in the data field. the mode is video the medium is visual the function is playing and verbal is false cancelrequest this component stops processing when it receives a cancelrequest it always performs a hard stop irrespective of the im request. cancelresponse standard pauserequest standard pauseresponse standard resumerequest standard resumeresponse standard extensionnotification this component does not use extensionnotification it ignores any extensionnotification events that are sent to it by the im. clearcontextrequest standard clearcontextresponse standard statusrequest standard statusresponse the component returns a standard life cycle response. the automaticupdate attribute is false because this component does not supply automatic updates. note standard means that the component does not do anything over and above the actions specified by the mmi architecture. 6.2 event syntax 6.2.1 examples of events for starting the component to start the component a startrequest event from the im to the display component is sent asking it to start a video display. it gives information about a video file in a certain uri. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startrequest source uri rtfuri context uri-1 requestid request-1 mmi data video-display-parameters videofile someuri mmi data mmi startrequest mmi mmi as part of support for the life-cycle events a modality component is required to respond to a startrequest event with a startresponse event. here s an example of a startresponse from the display component to the im informing the im that the component is successfully started and video is displaying. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri displayuri context uri-1 requestid request-1 status success mmi mmi here s an example of a startresponse event from the display component to the im in the case of failure with an example failure message. in this case the failure message indicates that the video codec is not supported. mmi xmlns http www.w3.org 2008 04 mmi-arch version 1.0 mmi startresponse source uri displayuri context uri-1 requestid request-1 status failure mmi statusinfo wvm codec not supported mmi statusinfo mmi startresponse mmi mmi a references mmi-arch multimodal architecture and interfaces working draft jim barnett et al. editors. this specification describes a loosely coupled architecture for multimodal user interfaces which allows for co-resident and distributed implementations and focuses on the role of markup and scripting and the use of well defined interfaces between its constituents. world wide web consortium 2011. mmif w3c multimodal interaction framework james a. larson t.v. raman and dave raggett editors world wide web consortium 2003. emma extensible multimodal annotation markup language emma michael johnson et al. editors. emma is an xml format for annotating application specific interpretations of user input with information such as confidence scores time stamps input modality and alternative recognition hypotheses world wide web consortium 2009. voicexml voice extensible markup language voicexml version 2.1 matt oshry et al. editors. world wide web consortium 2007. ssml speech synthesis markup language ssml version 1.1 daniel c. burnett et al. editors. world wide web consortium 2010. srgs speech recognition grammar specification version 1.0 andrew hunt et al. editors. world wide web consortium 2004. sisr semantic interpretation for speech recognition sisr version 1.0 luc van tichelen al. editors. world wide web consortium 2004. 