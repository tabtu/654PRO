best practices for publishing linked data best practices for publishing linked data w3c working group note 09 january 2014 this version http www.w3.org tr 2014 note-ld-bp-20140109 latest published version http www.w3.org tr ld-bp editors bernadette hyland 3 round stones inc. ghislain atemezing eurecom boris villaz n-terrazas isoco intelligent software components s.a. copyright 2014 w3c mit ercim keio beihang all rights reserved. w3c liability trademark and document use rules apply. abstract this document sets out a series of best practices designed to facilitate development and delivery of open government data as linked open data. linked open data makes the world wide web into a global database sometimes refered to as the web of data using linked data principles developers can query linked data from multiple sources at once and combine it without the need for a single common schema that all data shares. prior to international data exchange standards for data on the web it was time consuming and difficult to build applications using traditional data management techniques. as more open government data is published on the web best practices are evolving too. the goal of this document is to compile the most relevant data management practices for the publication and use of of high quality data published by governments around the world as linked open data. status of this document this section describes the status of this document at the time of its publication. other documents may supersede this document. a list of current w3c publications and the latest revision of this technical report can be found in the w3c technical reports index at http www.w3.org tr this document was published by the government linked data working group as a first public working group note. if you wish to make comments regarding this document please send them to public-gld-comments@w3.org subscribe archives all comments are welcome. since the working group s charter is ending the group might not officially respond to comments but individual members may. as usual comments are publicly archived available to both readers and any group updating this document in the future. publication as a working group note does not imply endorsement by the w3c membership. this is a draft document and may be updated replaced or obsoleted by other documents at any time. it is inappropriate to cite this document as other than work in progress. this document was produced by a group operating under the 5 february 2004 w3c patent policy. w3c maintains a public list of any patent disclosures made in connection with the deliverables of the group that page also includes instructions for disclosing a patent. an individual who has actual knowledge of a patent which the individual believes contains essential claim s must disclose the information in accordance with section 6 of the w3c patent policy. table of contents 1. prepare stakeholders 2. select a dataset 3. model the data 4. specify an appropriate license 5. the role of good uris for linked data 6. standard vocabularies 7. convert data to linked data 8. provide machine access to data 9. announce to the public 10. social contract of a linked data publisher a. acknowledgments b. references b.1 informative references audience readers of this document are expected to be familiar with fundamental web technologies such as html uris and http. the document is targeted at developers government information management staff and web site administrators. scope linked data refers to a set of best practices for publishing and interlinking structured data for access by both humans and machines via the use of the rdf resource description framework family of standards for data interchange rdf-concepts and sparql for query. rdf and linked data are not synonyms. linked data however could not exist without the consistent underlying data model that we call rdf rdf-concepts understanding the basics of rdf is helpful in leveraging linked data. background in recent years governments worldwide have mandated publication of open government content to the public web for the purpose of facilitating open societies and to support governmental accountability and transparency initiatives. in order to realize the goals of open government initiatives the w3c government linked data working group offers the following guidance to aid in the access and re-use of open government data. linked data provides a simple mechanism for combining data from multiple sources across the web. linked data addresses many objectives of open government transparency initiatives through the use international web standards for the publication dissemination and reuse of structured data. summary of best practices the following best practices are discussed in this document and listed here for convenience. step 1 prepare stakeholders prepare stakeholders by explaining the process of creating and maintaining linked open data. step 2 select a dataset select a dataset that provides benefit to others for reuse. step 3 model the data modeling linked data involves representing data objects and how they are related in an application-independent way. step 4 specify an appropriate license specify an appropriate open data license. data reuse is more likely to occur when there is a clear statement about the origin ownership and terms related to the use of the published data. step 5 good uris for linked data the core of linked data is a well-considered uri naming strategy and implementation plan based on http uris. consideration for naming objects multilingual support data change over time and persistence strategy are the building blocks for useful linked data. step 6 use standard vocabularies describe objects with previously defined vocabularies whenever possible. extend standard vocabularies where necessary and create vocabularies only when required that follow best practices whenever possible. step 7 convert data convert data to a linked data representation. this is typically done by script or other automated processes. step 8 provide machine access to data provide various ways for search engines and other automated processes to access data using standard web mechanisms. step 9 announce new data sets remember to announce new data sets on an authoritative domain. importantly remember that as a linked open data publisher an implicit social contract is in effect. step 10 recognize the social contract recognize your responsibility in maintaining data once it is published. ensure that the dataset s remain available where your organization says it will be and is maintained over time. 1. prepare stakeholders preparation is crucial for success of an information management project. sharing with government stakeholders the benefits of data sharing in terms of their agency mission or charter helps ensure success. the concepts of data modeling will be familiar to information management professionals. while the specifics of linked open data may be new to people who are used to traditional information manaagement approaches they are well-documented in w3c recommendations notes and many peer reviewed publications wood2013 howto-lodp bhyland2011 bvillazon linked data has entered the mainstream and is used by governments around the world major search engines international corporations and agile startups. to help prepare stakeholders we ve included three life cycle models however it is evident that they all share common and sometimes overlapping activities. for example they all identify the need to specify model and publish data in standard open web formats. in essence they capture the same tasks that are needed in the process but provide different boundaries between these tasks. one workflow is not better than another they are simply different ways to visualize a familiar information management process. hyland et al. bhyland2011 provide a six-step cookbook to model create publish and announce government linked data. they highlight the role of the world wide web consortium w3c which is currently driving specifications and best practices for the publication of governmental data. hyland et al. lifecycle consists of the following activities 1 identify 2 model 3 name 4 describe 5 convert 6 publish and 7 maintain. according to hausenblas et al. hausenblas existing data management approaches assume control over schema data and data generation which is not the case in the web because it is open de-centralized environment. based on their experience in linked data publishing and consumption over the past years they identify involved parties and fundamental phases which provide for a multitude of so called linked data life cycles that consist of the following steps 1 data awareness 2 modeling 3 publishing 4 discovery 5 integration and 6 use cases. villaz n-terrazas et al. propose in bvillazon a first step to formalize their experience gained in the development of government linked data into a preliminary set of methodological guidelines for generating publishing and exploiting linked government data. their life cycle consists of the following activities 1 specify 2 model 3 generate 4 publish and 5 exploit. 2. select a dataset when publishing a dataset select data that is uniquely collected or created by your organization. ideally this information when combined with other open data provides greater value. government agencies are in a unique position to collect and curate valuable datasets. since there is effort and cost associated with modeling publishing and maintaining any data set as a public service selection of high value data sets may be guided re-use potential and popularity among other factors. data about geographic features human health legislation population and demographics and the environmental data are just some of the popular open government data sets that have been published as linked open data. for example publishing regulated facilities that can then be linked with latitude and longitude allows the facilities to be plotted on a map. that data can then be extended using post codes allowing people to search via post code what facilities are near them on a map view. facilities data published as extensible linked data allows web developers to rapidly build web interfaces that are both useful to machines and humans. 3. model the data it is not within scope of this document to treat the linked open data modeling process comprehensively. rather we provide guidance on conducting linked data modeling and describe a few aspects that differentiate linked data modeling from other approaches. participants the modeling process should include participants who represent a broad range of concerns including the government program or office the data steward of the originating data source data standards and policies. for example if the source data is from a relational database the modeling meetings may include a database administrator dba and or data steward. if the organization has a data standards group include a stakeholder in the modeling effort. a linked data subject matter expert should facilitate the modeling process and be capable of explaining linked data principles and the data life cycle see prepare stakeholders the modeling phase may involve onsite or virtual meetings during which stakeholders specify details about the data including what the objects mean and how they are related to each other. the linked data subject matter expert typically records this information in order complete the remaining steps in the modeling process. understanding the differences linked data modeling involves data going from one model to another. for example modeling may involve converting a tabular representation of the data to a graph-based representation. often extracts from relational databases are modeled and converted to linked data to more rapidly integrate datasets from different authorities or with other open source datasets. during the data modeling process stakeholders are encouraged to describe how objects are related. the subject matter expert is recording how various objects are related using standard vocabularies wherever possible. best practices for using standard vocabularies are detailed later in this document. in linked data the data schema is represented with the data itself. this mechanism of self-describing data contrasts with the relational approach where external documents e.g. data dictionaries and diagrams e.g. entity relationship diagrams logical schemas describe the data. linked data modeling is differentiated through its use of international open web standards. linked data is predicated on the use of international standards for data interchange e.g. rdfa json-ld turtle and rdf xml and query sparql. linked data modeling leverages many of the advances in modern information management including increased levels of data abstraction. we hope that highlighting some of the differences proves helpful and better informs your efforts to publish open government data. 4. specify an appropriate license it is important to specify who owns data published on the web and to explicitely connect that license with the data itself. governmental authorities publishing open data are encouraged to review the relevant guidance for open licenses and copyright. publishing linked open data makes associating a license that travels with the data itself easier. people are more likely to reuse data when there is a clear acceptable license associated with it. a valuable resource for open data publishers may be found on the creative commons web site. creative commons develops supports and stewards legal and technical infrastructure for digital content publishing. 5. the role of good uris for linked data uri design principles the web makes use of the uri as a single global identification system. the global scope of uris promotes large-scale network effects therefore in order to benefit from the value of ld government and governmental agencies need to identify their resources using uris. this section provides a set of general principles aimed at helping government stakeholders to define and manage uris for their resources. use http uris to benefit from and increase the value of the world wide web governments and agencies should provide http uris as identifiers for their resources. there are many benefits to participating in the existing network of uris including linking caching and indexing by search engines. as stated in howto-lodp http uris enable people to look-up or dereference a uri in order to access a representation of the resource identified by that uri. to benefit from and increase the value of the world wide web data publishers should provide uris as identifiers for their resources. provide at least one machine-readable representation of the resource identified by the uri in order to enable http uris to be dereferenced data publishers have to set up the necessary infrastructure elements e.g. tcp-based http servers to serve representations of the resources they want to make available e.g. a human-readable html representation or a machine-readable turtle a publisher may supply zero or more representations of the resource identified by that uri. however there is a clear benefit to data users in providing at least one machine-readable representation. more information about serving different representations of a resource can be found in cooluris a uri structure will not contain anything that could change it is good practice that uris do not contain anything that could easily change or that is expected to change like session tokens or other state information. uris should be stable and reliable in order to maximize the possibilities of reuse that linked data brings to users. there must be a balance between making uris readable and keeping them more stable by removing descriptive information that will likely change. for more information on this see architecture of the world wide web uri persistence. uri opacity the architecture of the world wide web webarch provides best practices for the treatment of uris at the time they are resolved by a web client agents making use of uris should not attempt to infer properties of the referenced resource. uris should be constructed in accordance with the guidance provided in this document to ensure ease of use during development and proper consideration to the guidelines given herein. however web clients accessing such uris should not parse or otherwise read into the meaning of uris. uri policy for persistence defining and documenting a persistent uri policy and implementation plan is vital to the ongoing success and stability of publishing open government data. the effect of changing or moving resources has the effect of breaking applications dependent upon it. therefore government authorities should define a persistence strategy and implementation plan to provide content using the same web address even though the resources in question may have moved. persistent identifiers are used to retain addresses to information resources over the long term. persistent identi ers are used to uniquely identify objects in the real world and concepts in addition to information resources. the choice of a particular uri scheme provides no guarantee that those uris will be persistent. uri persistence is a matter of policy and commitment on the part of the uri owner. http rfc2616 has been designed to help manage uri persistence. for example http redirection using the 3xx response codes permits servers to tell an agent that further action needs to be taken by the agent in order to fulfill the request for example a new uri is associated with the resource the purl concept allows for generalized url curation of http uris on the world wide web. purls allow third party control over both url resolution and resource metadata provision. a persistent url is an address on the world wide web that causes a redirection to another web resource. if a web resource changes location and hence url a purl pointing to it can be updated. a user of a purl always uses the same web address even though the resource in question may have moved. purls may be used by publishers to manage their own information space or by web users to manage theirs a purl service is independent of the publisher of information. purl services thus allow the management of hyperlink integrity. hyperlink integrity is a design trade-off of the world wide web but may be partially restored by allowing resource users or third parties to influence where and how a url resolves. the open source purls project is used widely to run persistent identifier management sites. the open source purls project is used by libraries academic organizations government agencies and non-government organizations around the world. for example persistent urls are used by the united nations food and agriculture organization fao to provide uris for major food crops. the national center for biomedical ontology provides persistent urls to unify and address the terminology used in many existing biomedical databases. the us government printing office also uses persistent urls to point to documents like the u.s. budget that are deemed essential to a democratic transparent government. recently a software project called permanent identifiers for the web emerged to provide a secure permanent url re-direction service for web applications. the service operates in https-only mode to ensure end-to-end security. this means that it may be used for linked data applications that require high levels of security such as those found in the financial medical and public infrastructure sectors. a growing group of organizations that have pledged responsibility to ensure the operation of this website over time. those interested in learning more are encouraged to contact the w3c permanent identifier community group. purls implement one form of persistent identi er for virtual resources. other persistent identi er schemes include digital object identi ers dois life sciences identi ers lsids and info uris. all persistent identi cation schemes provide unique identi ers for possibly changing virtual resources but not all schemes provide curation opportunities. curation of virtual resources has been de ned as the active involvement of information professionals in the management including the preservation of digital data for future use. yakel-07 for a persistent identi cation scheme to provide a curation opportunity for a virtual resource it must allow real-time resolution of that resource and also allow real-time administration of the identi er. uri construction the following guidance is has been developed by organizations involved in uri strategy and implementation for government agencies cool uris for the semantic web cooluris designing uri sets for the uk public sector uk-govuri designing uri sets for the uk public sector a document from the uk cabinet offices that defines the design considerations on how to uris can be used to publish public sector reference data study on persistent uris with identification of best practices and recommendations on the topic for the member states and the european commission puri towards a nl uri strategy general-purpose guidelines exist for the uri designer to consider including cool uris for the semantic web which provides guidance on how to use uris to describe things that are not web documents style guidelines for naming and labeling ontologies in the multilingual web pdf internationalized resource identifiers stakeholders who are planning to create uris using characters that go beyond the subset defined in rfc3986 are encouraged to reference iris. defined in rfc 3987 iri is a protocol element that represents a complement to the uniform resource identifier uri an iri is a sequence of characters from the universal character set unicode iso 10646 that can be therefore used to mint identifiers that use a wider set of characters than the one defined in rfc3986 the internationalized domain name or idn is a standard approach to dealing with multilingual domain names was agreed by the ietf in march 2003. internationalized resource identifiers use non-ascii characters in uris which is relevent to those organizations interested in minting uris in languages including german dutch spanish french and chinese. although there exist some standards focused on enabling the use of international characters in web identifiers government stakeholders need to take into account several issues before constructing such internationalized identifiers. this section is not exhaustive and the editors point the interested audience to an introduction to multilingual web addresses however some of the most relevant issues are following domain name lookup numerous domain name authorities already offer registration of internationalized domain names. these include providers for top level country domains as cn jp kr etc. and global top level domains such as info org and museum. domain names and phishing one of the problems associated with idn support in browsers is that it can facilitate phishing through what are called homograph attacks consequently most browsers that support idn also put in place some safeguards to protect users from such fraud. encoding problems iri provides a standard way for creating and handling international identifiers however the support for iris among the various semantic web technology stacks and libraries is not uniform and may lead to difficulties for applications working with this kind of identifiers. a good reference on this subject can be found in i18n-web the uri syntax defined in rfc3986 std 66 uniform resource identifier uri generic syntax restricts uris to a small number of characters basically just upper and lower case letters of the english alphabet european numerals and a small number of symbols. 6. standard vocabularies standardized vocabularies should be reused as much as possible to facilitate inclusion and expansion of the web of data. the w3c has published several useful vocabularies for linked data. for example the following standard vocabularies help developers to describe basic or more complex relationships for describing data catalogs organizations and multidimensional data such as statistics on the web. government publishers are encouraged to use standardized vocabularies rather than reinventing the wheel wherever possible. specifically data catalog vocabulary dcat vocab-dcat is an rdf vocabulary designed to facilitate interoperability between data catalogs published on the web. by using dcat to describe datasets in data catalogs publishers increase discoverability and enable applications easily to consume metadata from multiple catalogs. it further enables decentralized publishing of catalogs and facilitates federated dataset search across sites. aggregated dcat metadata can serve as a manifest file to facilitate digital preservation. organizational structures and activities are often described by government authorities. the organization ontology vocab-org supports the publishing of organizational information across a number of domains as linked data. the organizational ontology is designed to allow domain-specific extensions to add classification of organizations and roles as well as extensions to support neighboring information such as organizational activities. many government agencies publish statistical information on the public web. the data cube vocabulary vocab-data-cube provides a means to do this using the resource description framework rdf the rdf data cube vocabulary makes it possible to discover and identify statistical data artifacts in a uniform way. csarven the model underpinning the data cube vocabulary is compatible with the cube model that underlies sdmx statistical data and metadata exchange an iso standard for exchanging and sharing statistical data and metadata among organizations. the data cube vocabulary is a core foundation which supports extension vocabularies to enable publication of other aspects of statistical data flows or other multi-dimensional datasets. how to find existing vocabularies there are search tools that collect analyze and index vocabularies and semantic data available online for efficient access. search tools that use structured data represented as linked data include falcons watson sindice semantic web search engine swoogle and schemapedia others include the lov directory prefix.cc bioportal biological domain and the european commission s joinup platform. where to find existing vocabularies in data catalogues another way around is to perform search using the previously identified key terms in datasets catalogs. some of these catalogs provide samples of how the underlying data was modeled and used. vocabulary checklist this section provides a set of considerations aimed at helping stakeholders review a vocabulary to evaluate its usefulness. note it is best practice to use or extend an existing vocabulary before creating a new vocabulary. a basic vocabulary checklist ensure vocabularies you use are published by a trusted group or organization ensure vocabularies have permanent uris and confirm the versioning policy. vocabularies must be documented a vocabulary must be documented. this includes the liberal use of labels and comments as well as appropriate language tags. the publisher must provide human-readable pages that describe the vocabulary along with its constituent classes and properties. preferably easily comprehensible use-cases should be defined and documented. vocabularies should be self-descriptive each property or term in a vocabulary should have a label definition and comment defined. self-describing data suggests that information about the encodings used for each representation is provided explicitly within the representation. the ability for linked data to describe itself to place itself in context contributes to the usefulness of the underlying data. for example the widely-used dublin core vocabulary formally dcmi metadata terms has a term name contributor which has a label contributor definition an entity responsible for making contributions to the resource comment examples of a contributor include a person an organization or a service. vocabularies should be described in more than one language multilingualism should be supported by the vocabulary i.e. all the elements of the vocabulary should have labels definitions and comments available in the government s official language s e.g. spanish and at least in english. this is also important as the documentation should suppoly appropriate tags for the language used for the comments or labels. for example for the same term contributor rdfs label contributor en colaborador es rdfs comment examples of a contributor include a person an organization or a service en ejemplos de collaborator incluyen persona organizaci n o servicio es vocabularies should be used by other datasets if the vocabulary is used by other authoritative linked open datasets that is helpful. it is in re-use of vocabularies that we achieve the benefits of linked open data. selected vocabularies from third parties should be already in use by other datasets as this shows that they are already established in the lod community and thus better candidates for wider adoption and reuse. for example an uow.acc.tab.analysis on the use of vocabularies on the linked data cloud reveals that foaf is reused by more than 55 other vocabularies. vocabularies should be accessible for a long period the vocabulary selected should provide some guarantee of maintenance over a specified period ideally indefinitely. vocabularies should be published by a trusted group or organization although anyone can create a vocabulary it is always better to check if it is one person group or authoritative organization that is responsible for publishing and maintaining the vocabulary. vocabularies should have persistent urls persistent access to the server hosting the vocabulary facilitating reusability is necessary. example the geo w3c vocabulary vocab-geo is one of the most used vocabularies for a basic representation of geometry points latitute longitude and has been around since 2009 always available at the same namespace. vocabularies should provide a versioning policy the publisher ideally will address compatibility of versions over time. major changes to the vocabularies should be reflected in the documentation. vocabulary creation this section provides a set of informative considerations aimed at stakeholders who decide they must develop their own vocabularies. define the uri of the vocabulary. the uri that identifies your vocabulary must be defined. this is strongly related to the best practices described in section uri construction. for example if we are minting new vocabulary terms from a particular government we should define the uri of that particular vocabulary. uris for properties with non-literal ranges what it means name all properties as verb senses so that triples may be actually read e.g. hasproperty vocabularies should be self-descriptive what it means each property or term in a vocabulary should have a label definition and comment defined. self-describing data suggests that information about the encodings used for each representation is provided explicitly within the representation. the ability for linked data to describe itself to place itself in context contributes to the usefulness of the underlying data. for example the widely-used dublin core vocabulary formally dcmi metadata terms has a term name contributor which has a label contributor definition an entity responsible for making contributions to the resource comment examples of a contributor include a person an organization or a service. vocabularies should be described in more than one language multilingualism should be supported by the vocabulary i.e. all the elements of the vocabulary should have labels definitions and comments available in the government s official language e.g. spanish and at least in english. that is also very important as the documentation should be clear enough with appropriate tag for the language used for the comments or labels. for example for the same term contributor rdfs label contributor en colaborador es rdfs comment examples of a contributor include a person an organization or a service en ejemplos de collaborator incluyen persona organizaci n o servicio es vocabularies should provide a versioning policy it refers to the mechanism put in place by the publisher to always take care of backward compatibilities of the versions the ways those changes affected the previous versions. major changes of the vocabularies should be reflected on the documentation in both machine or human-readable formats. vocabularies should provide documentation a vocabulary should be well-documented for machine readable use of labels and comments tags to language used also for human-readable an extra documentation should be provided by the publisher to better understand the classes and properties and if possible with some valuable use cases. provide human-readable documentation and basic metadata such as creator publisher date of creation last modification version number. vocabularies should be published following available best practices publish your vocabulary on the web at a stable uri using an open license.. one of the goals is to contribute to the community by sharing the new vocabulary. to this end it is recommended to follow available recipes for publishing rdf vocabularies e.g. best practice recipes for publishing rdf vocabularies bp-pub using skos to create a controlled vocabulary skos the simple knowledge organization system skos-reference is a w3c standard based on other semantic web standards rdf and owl that provides a way to represent controlled vocabularies taxonomies and thesauri. specifically skos itself is an owl ontology and it can be written out in any rdf flavor. the w3c skos standard defines a portable flexible controlled vocabulary format that is increasingly popular with the added benefit of a good entry-level step toward the use of semantic web technology. skos is appropriate in the following situations there is a need to publish a controlled list of terms or taxonomies having a special meaning for the domain. the complexity and formality of an owl ontology is not appropriate for example the terms are not themselves entities that will be richly described in creating a skos vocabulary bear the following good practice in mind make a clear distinction between the collections of concepts conceptscheme and the different individual concepts. define when possible a different namespace for each skos conceptscheme structure the concepts in the list using properties skos hastopconcept skos broader skos narrower. consider defining a class to represent all the skos concepts in your controlled list this can facilitate declaration of properties that will use this list provide multilingual labels for the terms. multilingual vocabularies this section is not comprehensive however is intended to mention some of the issues identified by the working group and some of the work performed by others in relation to publishing linked data in multiple languages. for more details on the multilingualism on the web see the multilingualweb-lt working group multilingual vocabularies broaden search as of the writing of this note many of the available linked data vocabularies are in english. this may restrict your content from being searched by multilingual search engines and by non-english speakers. if designing a vocabulary provide labels and descriptions if possible in several languages to make the vocabulary usable by a global audience. multilingual vocabularies may be found in the following formats as a set of rdfs label in which the language has been restricted en fr... currently this is the most commonly used approach. as skos preflabel or skosxl label in which the language has also been restricted. as a set of monolingual ontologies ontologies in which labels are expressed in one natural language in the same domain mapped or aligned to each other see the example of eurowordnet in which wordnets in different natural languages are mapped to each other through the so-called ili inter-lingual-index- which consists of a set of concepts common to all categorizations as a set of ontology lexicon. this is an approach to the representation of linguistic multilingual information associated to ontologies. the idea is that the ontology is associated to an external ontology of linguistic descriptions. one of the best exponents in this case is the lemon model an ontology of linguistic descriptions that is to be related with the concepts and properties in an ontology to provide lexical terminological morphosyntactic etc. information. one of the main advantages of this approach is that semantics and linguistic information are kept separated. one can link several lemon models in different natural languages to the same ontology. a list of codes and their corresponding uris for the representation of language names is published and maintained by the official registration authority of iso639-2 the us library of congress. iso-639-1 iso-639-2 note the current trend is to follow the first approach i.e. to use at least a rdfs label and rdfs comment for each term in the vocabulary. 7. convert data to linked data now with the ground work in place the next step is to actually convert a dataset into a linked data representation. there is more than one way to convert data including scripts declarative mapping languages languages that perform query translation rather then data translation e.g. r2rml regardless of which approach is used data conversion involves mapping the source data into a set of rdf statements. as data is converted data is serialized into rdf statements. rdf can be converted into a range of rdf serializations that include rdfa json-ld turtle and n-triples rdf xml linked data modelers and developers have certain reasons they prefer to use one rdf serialization over another. no one rdf serialization is better than the other. benefits of using one over another include simplicity ease of reading for a human and speed of processing. provide basic metadata when modeling linked data metadata it is a best practice to include the mime type publishing organization and or agency creation date modification date version frequency of updates and contact email address if this information is available and appropriate to the data. in subsequent sections we outline guidance for the use of vocabularies as well as a vocabulary checklist to assist in the modeling process. link to other stuff as the name suggests linked open data means the data links to other stuff. data in isolation is rarely valuable however interlinked data is suddenly very valuable. there are many popular datasets such as dbpedia that provide valuable data including photos and geographic information. being able to connect data from a government authority with dbpedia for example is quick way to show the value of adding content to the linked data cloud. 8. provide machine access to data a major benefit of linked data is that it provides access to data for machines. machines can use a variety of methods to read data including but not limited to direct uri resolution follow your nose a restful api a sparql endpoint and or via file download. the sparql protocol and rdf query language sparql defines a query language for rdf data analogous to the structured query language sql for relational databases. sparql is to rdf data what sql is to a relational database. for more information see the sparql 1.1 overview sparql11-overview a sparql endpoint is a a service that accepts sparql queries and returns answers to them as sparql result sets. it is a best practice for datasets providers to give the url of their sparql endpoint to allow access to their data programmatically or through a web interface. a list of sparql endpoints monitoring the availability performance interoperability and discoverability of sparql endpoints is published by the open knowledge foundation. 9. announce to the public it is not within scope of this document to discuss domain name issues and data hosting however it is a vital part of the publication process. hosting linked open data may require involvement with agency system security staff and require planning that often takes considerable time and experise for compliance so involve stakeholders early and schedule accordingly. now you re ready to point people to authoritative open government data. be sure the datasets are available via an authoritative domain. using an authoritative domain increases the perception of trusted content. authoritative data that is regularly updated on a government domain is critical to re-use of authoritative datasets. the following checklist is intended to help organizations realize the benefits of publishing open government data as well as communicate to the public that you are serious about providing this data over time. use multiple channels including mailing lists blogs and newsletters to announce a newly published data set publish a description for each published dataset using vocab-dcat or void vocabulary define the frequency of data updates as metadata associate an appropriate license plan and implement a persistence strategy ensure data is accurate to the greatest degree possible provide a form for people to report problematic data and give feedback provide a contact email address alias for those responsible for curating and publishing the data and ensure staff have the necessary training to respond in a timely manner to feedback. 10. social contract of a linked data publisher government publishers of linked open data are entering into a sort of social contract with users of their data. publishers must recognize their responsibility in maintaining data once it is published. key to both access and reuse is ensuring that the dataset s your organization publishes remains available where you say it will be and is maintained over time. giving due consideration to your organization s uri strategy should be one of the first activities your team undertakes as they prepare a linked open data strategy. authoritative data requires the permanence and resolution of http uris. if publishers move or remove data that was published to the web third party applications or mashups may break. this is considered rude for obvious reasons and is the basis for the linked data social contract. a good way to prevent causing http 404s is for your organization to implement a persistence strategy. below we provide an introduction to the best practice of defining a persistence strategy and implementation plan. stability properties it is beyond the scope of this document to comprehensively treat issues related to data stability over time on the web. mention is included such that readers may consider data stability in the context of a given agency and region. there are characteristics that influence the stability or longevity of useful open government data. many of these properties are not unique to government linked open data yet they influence data cost and therefore data value. as a final note related to the importance of stability. the w3c prepares to celebrate its 20th anniversary and the web turns 25 years old in 2014. perhaps surprisingly the first web page cannot be found. a team at cern is looking into restoring it however at the time of the writing of this document it has not yet been found. gbrumfiel thus the government linked data working group wished to reference the importance of data stability as the vast majority of government data is quickly available only in digital form. as stewards and supporters of open government data it is encumbant upon us all to pursue the methods and tools to support responsible data stability on the web over time. thanks for your interest in this topic and please join us in helping evolve the web of data into the 21st century and beyond a. acknowledgments the editors wish to gratefully acknowledge the considerable contributions to the linked data best practices document by the following people dave reynolds epimorphics uk phil archer w3c ercim uk makx dekkers independent consultant spain john erickson rensselaer polytechnic institute usa jo o paulo almeida federal university of esp rito santo brazil tom heath open data institute uk thomas baker dublin core metadata initiative us sarven capadisli uk bernard vatant mondeca france michael pendleton u.s. environmental protection agency usa biplav srivastava ibm india daniel vila ontology engineering group universidad polit cnica de madrid upm spain mart n lvarez espinar ctic-centro tecnol gico spain david wood 3 round stones usa michael hausenblas mapr usa our working group co-chair hadley beeman uk linkedgov uk and sandro hawke w3c mit please accept our apologies in advance if we ve inadvertantly omitted your name as many people provided valuable feedback and were instrumental in the production of this best practices publication. thank you grazie gracias obrigado merci this document has been produced by the government linked data working group and its contents reflect extensive discussion within the working group as a whole. b. references b.1 informative references bhyland2011 bernadette hyland david wood. the joy of data cookbook for publishing linked government data on the web. url http www.w3.org 2011 gld wiki linked_data_cookbook bvillazon boris villaz n-terrazas et al.. methodological guidelines for publishing government linked data. url http link.springer.com chapter 10.1007 978-1-4614-1767-5_2 cooluris leo sauermann richard cyganiak. cool uris for the semantic web. 3 december 2008. w3c note. url http www.w3.org tr cooluris csarven sarven capadisli. towards linked statistical data analysis. url http csarven.ca linked-statistical-data-uow.acc.tab.analysis gbrumfiel geoff brumfiel. the first web page amazingly is lost. url http www.npr.org 2013 05 22 185788651 the-first-web-page-amazingly-is-lost hausenblas michael hausenblas richard cygankiak. linked data life cycles formerly at http linked-data-life-cycles.info iso-639-1 u.s. library of congress. iso 639-1 codes for the representation of names of languages part 1 two letter codes for languages. url http id.loc.gov vocabulary iso639-1.html iso-639-2 u.s. library of congress. iso 639-2 codes for the representation of names of languages part 2 alpha-3 code for the names of lanuguages. url http id.loc.gov vocabulary iso639-2.html puri phil archer et al.. study on persistent uris. url http philarcher.org diary 2013 uripersistence recs rdf-concepts graham klyne jeremy carroll. resource description framework rdf concepts and abstract syntax. 10 february 2004. w3c recommendation. url http www.w3.org tr rdf-concepts rfc2616 r. fielding et al. hypertext transfer protocol http 1.1. june 1999. rfc. url http www.ietf.org rfc rfc2616.txt rfc3986 t. berners-lee r. fielding l. masinter. uniform resource identifier uri generic syntax rfc 3986 january 2005. rfc. url http www.ietf.org rfc rfc3986.txt skos-reference alistair miles sean bechhofer. skos simple knowledge organization system reference. 18 august 2009. w3c recommendation. url http www.w3.org tr skos-reference wood2013 wood d. zaidman m. ruth l.. linked data structured data on the web. url http www.manning.com dwood bp-pub diego berrueta jon phipps. best practice recipes for publishing rdf vocabularies. w3c working group note. url http www.w3.org tr swbp-vocab-pub howto-lodp christian bizer richard cyganiak tom heath. how to publish linked data on the web. url http linkeddata.org docs how-to-publish i18n-web s. auer m. weidl j. lehmann amrapali j. zaveri key-sun choi. i18n of semantic web applications. url http svn.aksw.org papers 2010 iswc_i18n public.pdf sparql11-overview the w3c sparql working group. sparql 1.1 overview. 21 march 2013. w3c recommendation. url http www.w3.org tr sparql11-overview uk-govuri cabinet office gov.uk. designing uri sets for the uk public sector. url https www.gov.uk government publications designing-uri-sets-for-the-uk-public-sector vocab-data-cube richard cyganiak dave reynolds. the rdf data cube vocabulary. 17 december 2013. w3c proposed recommendation. url http www.w3.org tr vocab-data-cube vocab-dcat fadi maali john erickson. data catalog vocabulary dcat 17 december 2013. w3c proposed recommendation. url http www.w3.org tr vocab-dcat vocab-geo dan brickley tim berners-lee. basic geo wgs84 lat long vocabulary. url http www.w3.org 2003 01 geo vocab-org dave reynolds. the organization ontology. 17 december 2013. w3c proposed recommendation. url http www.w3.org tr vocab-org void keith alexander richard cyganiak michael hausenblas jun zhao. describing linked datasets with the void vocabulary. 3 march 2011. w3c note. url http www.w3.org tr void webarch ian jacobs norman walsh. architecture of the world wide web volume one. 15 december 2004. w3c recommendation. url http www.w3.org tr webarch yakel-07 elizabeth yakel. digital curation. url http dx.doi.org 10.1108 10650750710831466 